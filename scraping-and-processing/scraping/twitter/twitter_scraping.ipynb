{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Scraping\n",
    "\n",
    "### Verwendete Biblioteken:\n",
    "- SNScraper (https://github.com/JustAnotherArchivist/snscrape)\n",
    "- Pandas (Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping hrPresse\n",
      "Finished scraping hessenschau\n",
      "Finished scraping BR_Presse\n",
      "Finished scraping MDRAktuell\n",
      "Finished scraping mdr_th\n",
      "Finished scraping MDR_SAN\n",
      "Finished scraping MDR_SN\n",
      "Finished scraping mdrde\n",
      "Finished scraping WDR2\n",
      "Finished scraping WDR\n",
      "Finished scraping WDRaktuell\n",
      "Finished scraping tagesschau\n",
      "Finished scraping welt\n",
      "Finished scraping derspiegel\n",
      "Finished scraping ndr\n",
      "Finished scraping NDRinfo\n",
      "Finished scraping SWRAktuellBW\n",
      "Finished scraping swr3\n",
      "Finished scraping faznet\n",
      "Finished scraping SZ\n",
      "scraping completed\n"
     ]
    }
   ],
   "source": [
    "def build_string(username, date):\n",
    "    return \"snscrape --jsonl --since=\" + date + \" twitter-user \" + username + \" >twitter_data/\"+ username +\".txt\"\n",
    "\n",
    "for i in open(\"profiles.txt\").readlines():\n",
    "    s = i[:-1]\n",
    "    bashCommand = build_string(s, \"2020-01-01\")\n",
    "    print(\"Start scraping\", s)\n",
    "    os.system('cmd /c' + bashCommand)\n",
    "    print(\"Finished scraping\", s)\n",
    "print(\"scraping completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatText(text):\n",
    "    # remove Uni-Code\n",
    "    t = text.encode('latin-1', 'ignore').decode('latin-1')\n",
    "    \n",
    "    # Hashtags entfernen\n",
    "    t = re.sub(r'#\\w+', '', t)\n",
    "    \n",
    "    # Links entfernen\n",
    "    t = re.sub(r'http\\S+', '', t)\n",
    "    \n",
    "    # remove Steuersymbole/andere Zeichen\n",
    "    t = re.sub(r'[\\n\\t\\ \\\"\\':+?!]+', ' ', t)\n",
    "    \n",
    "    return t.upper()\n",
    "\n",
    "def frameToDic(dataframe):\n",
    "    dic = {}\n",
    "    for i in dataframe['text'].to_numpy():\n",
    "        for t in i.split():\n",
    "            if (t in dic):\n",
    "                dic[t] += 1\n",
    "            else:\n",
    "                dic[t] = 1\n",
    "    return dic\n",
    "\n",
    "def get_top_k(dictionary, k):\n",
    "    sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['date', 'user', 'likes', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"tagesschau.txt\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "c = 0\n",
    "\n",
    "for line in f:\n",
    "    temp = json.loads(line[:-1])\n",
    "    text = temp['content']\n",
    "    if \"corona\" in text.lower():\n",
    "        text = formatText(text)  # Remove unwanted content\n",
    "        user = temp['user']['username']  # Get Twitter Name\n",
    "        date = temp['date'][:10]  # Get date | YYYY-MM-DD\n",
    "        likes = temp['likeCount']  # Get \"likes\" bzw favorites\n",
    "        df = df.append({'date': date, 'user': user,\n",
    "                    'likes': likes, 'text': text}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame = pd.DataFrame(columns=['date', 'dic'])\n",
    "for i in df['date'].unique():\n",
    "    frame = df[df['date'] == i]\n",
    "    dic_frame = dic_frame.append({'date': i, 'dic': frameToDic(frame)}, ignore_index=True)\n",
    "# dic_frame.to_csv(\"dictionary_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrPresse\n",
      "hessenschau\n",
      "BR_Presse\n",
      "MDRAktuell\n",
      "mdr_th\n",
      "MDR_SAN\n",
      "MDR_SN\n",
      "mdrde\n",
      "WDR2\n",
      "WDR\n",
      "WDRaktuell\n",
      "tagesschau\n",
      "welt\n",
      "derspiegel\n",
      "ndr\n",
      "NDRinfo\n",
      "SWRAktuellBW\n",
      "swr3\n",
      "faznet\n",
      "SZ\n"
     ]
    }
   ],
   "source": [
    "for i in open(\"profiles.txt\").readlines():\n",
    "    s = i[:-1]\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
